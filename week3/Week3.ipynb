{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-23T13:24:31.737025Z",
     "start_time": "2025-03-23T13:24:31.734328Z"
    }
   },
   "source": [
    "from week3.utils import simple_tokenize\n",
    "\n",
    "sent = 'Thomas Jefferson began building Monticello age of 26.'\n",
    "token = sent.split()\n",
    "print(token)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Jefferson', 'began', 'building', 'Monticello', 'age', 'of', '26.']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T13:25:40.642429Z",
     "start_time": "2025-03-23T13:25:40.639715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sent = 'Thomas Jefferson began building Monticello age of 26.'\n",
    "sent = sent.lower()\n",
    "sent = sent.replace('.', ' .')\n",
    "token = sent.split()\n",
    "print(token)"
   ],
   "id": "4a5a66e04f443bd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thomas', 'jefferson', 'began', 'building', 'monticello', 'age', 'of', '26', '.']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T13:28:41.591648Z",
     "start_time": "2025-03-23T13:28:41.588263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "sent = 'Hello!!  Python. Coding,  Programming, Study..'\n",
    "delim = re.compile(r'[-\\s.,!@;?]+')\n",
    "token = delim.split(sent)\n",
    "print(token)\n",
    "if token[-1] == '' : \n",
    "    token = token[:-1]\n",
    "print(token)"
   ],
   "id": "b7bf1c851e6bbf60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Python', 'Coding', 'Programming', 'Study', '']\n",
      "['Hello', 'Python', 'Coding', 'Programming', 'Study']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T13:32:52.946550Z",
     "start_time": "2025-03-23T13:32:52.127710Z"
    }
   },
   "cell_type": "code",
   "source": " !pip install nltk",
   "id": "2bfc4cebf2b851cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/homebrew/anaconda3/lib/python3.12/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: click in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\r\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T13:33:40.434058Z",
     "start_time": "2025-03-23T13:33:39.899752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "nltk.download('punkt_tab') #구두점 데이터 다운로드\n",
    "\n",
    "sent = \"Hi! Python. Coding,   isn't, Study..\"\n",
    "\n",
    "token1 = word_tokenize(sent)\n",
    "token2 = TreebankWordTokenizer().tokenize(sent)\n",
    "\n",
    "print(token1)\n",
    "print(token2)"
   ],
   "id": "bec42990c6dd2556",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/iseongjun1/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', '!', 'Python', '.', 'Coding', ',', 'is', \"n't\", ',', 'Study', '..']\n",
      "['Hi', '!', 'Python.', 'Coding', ',', 'is', \"n't\", ',', 'Study..']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T13:36:56.141103Z",
     "start_time": "2025-03-23T13:36:56.136658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import txtutils as tu #util 패키지에서 txtutils를 포함하여 tu로 사용한다.\n",
    "\n",
    "doc = 'simple tokenize function test.'\n",
    "token = tu.simple_tokenize(doc)\n",
    "print(token)\n"
   ],
   "id": "71c1bd8adbdffdf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simple', 'tokenize', 'function', 'test', '.']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:00:49.516761Z",
     "start_time": "2025-03-23T14:00:49.513070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.txtutils import  simple_tokenize\n",
    "\n",
    "docs = []\n",
    "docs.append(\"I am going to go to the store.\")\n",
    "docs[0] = simple_tokenize(docs[0])\n",
    "docs.append(\"The Science of today is the technology of tommorow.\")\n",
    "docs[1] = simple_tokenize(docs[1])\n",
    "docs.append(\"You are using pip version 3.\")\n",
    "docs[2] = simple_tokenize(docs[2]) \n",
    "docs.append(\"Could not install packages due to an Error.\")\n",
    "docs[3] = simple_tokenize(docs[3])\n",
    "print(docs)"
   ],
   "id": "aeca9f18b13ea487",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', '.'], ['the', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tommorow', '.'], ['you', 'are', 'using', 'pip', 'version', '3', '.'], ['could', 'not', 'install', 'packages', 'due', 'to', 'an', 'error', '.']]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:03:02.287157Z",
     "start_time": "2025-03-23T14:03:02.283106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "docs = []\n",
    "docs.append(\"I am going to go to the store.\")\n",
    "docs.append(\"The Science of today is the technology of tommorow.\")\n",
    "docs.append(\"You are using pip version 3.\")\n",
    "docs.append(\"Could not install packages due to an Error.\")\n",
    "\n",
    "tk = TreebankWordTokenizer()\n",
    "tokens = []\n",
    "for doc in docs:\n",
    "    token = tk.tokenize(doc.lower())\n",
    "    tokens.append(token)\n",
    "print(tokens)"
   ],
   "id": "8a3a5f93747ee233",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'am', 'going', 'to', 'go', 'to', 'the', 'store', '.'], ['the', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tommorow', '.'], ['you', 'are', 'using', 'pip', 'version', '3', '.'], ['could', 'not', 'install', 'packages', 'due', 'to', 'an', 'error', '.']]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:07:02.388806Z",
     "start_time": "2025-03-23T14:07:02.384335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = '\\n'.join(docs)\n",
    "print(text)"
   ],
   "id": "9b23847355a571ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to go to the store.\n",
      "The Science of today is the technology of tommorow.\n",
      "You are using pip version 3.\n",
      "Could not install packages due to an Error.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T14:07:12.997095Z",
     "start_time": "2025-03-23T14:07:12.975006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = '\\n'.join(docs)\n",
    "sentences = sent_tokenize(text) #문장 토큰화\n",
    "print(sentences)\n",
    "tokens = [word_tokenize(t) for t in sentences]\n",
    "print(tokens)"
   ],
   "id": "3a11e3e9a46ff0d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am going to go to the store.', 'The Science of today is the technology of tommorow.', 'You are using pip version 3.', 'Could not install packages due to an Error.']\n",
      "[['I', 'am', 'going', 'to', 'go', 'to', 'the', 'store', '.'], ['The', 'Science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tommorow', '.'], ['You', 'are', 'using', 'pip', 'version', '3', '.'], ['Could', 'not', 'install', 'packages', 'due', 'to', 'an', 'Error', '.']]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d85b39c5b316b1fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

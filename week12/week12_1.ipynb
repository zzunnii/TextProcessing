{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T06:20:31.266285Z",
     "start_time": "2025-06-02T06:20:30.134172Z"
    }
   },
   "source": [
    "from nltk import FreqDist\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from konlpy.tag import Okt  # 한글 형태소 분석기 추가\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# NLTK 데이터 다운로드\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "except:\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T06:20:33.737748Z",
     "start_time": "2025-06-02T06:20:33.730744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "korean_stopwords = [\n",
    "    '이', '그', '저', '것', '들', '는', '은', '이', '가', '을', '를', \n",
    "    '에', '의', '와', '과', '도', '만', '에서', '로', '으로', '부터', \n",
    "    '까지', '이다', '하다', '되다', '있다', '없다', '같다', '다르다',\n",
    "    '그리고', '그런데', '하지만', '그러나', '또한', '그래서', '따라서',\n",
    "    '그냥', '정말', '진짜', '매우', '너무', '아주', '좀', '조금',\n",
    "    '약간', '살짝', '많이', '적게', '빨리', '천천히'\n",
    "]"
   ],
   "id": "d64ad61fce639c9c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T06:25:50.508301Z",
     "start_time": "2025-06-02T06:25:50.503300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def buildDict_korean(docs):\n",
    "    \"\"\"\n",
    "    한글 문서들로부터 사전 구축\n",
    "    \"\"\"\n",
    "    okt = Okt()\n",
    "    doc_tokens = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        # 한글 형태소 분석 및 품사 태깅\n",
    "        tokens = okt.morphs(doc, stem=True)  # 어간 추출 포함\n",
    "        # 불용어 제거 및 한글만 필터링\n",
    "        tokens = [token for token in tokens \n",
    "                 if token not in korean_stopwords \n",
    "                 and len(token) > 1  # 한 글자 단어 제거\n",
    "                 and re.match(r'^[가-힣]+$', token)]  # 한글만 허용\n",
    "        doc_tokens.append(tokens)\n",
    "    \n",
    "    # 전체 토큰들을 평면화하여 빈도 계산\n",
    "    all_tokens = []\n",
    "    for tokens in doc_tokens:\n",
    "        all_tokens.extend(tokens)\n",
    "    \n",
    "    vocab = FreqDist(all_tokens)\n",
    "    vocab = vocab.most_common()\n",
    "    \n",
    "    word_to_id = {word[0]: id for id, word in enumerate(vocab)}\n",
    "    id_to_word = {id: word[0] for id, word in enumerate(vocab)}\n",
    "    \n",
    "    # 전체 코퍼스를 단어 ID 배열로 변환\n",
    "    corpus = []\n",
    "    for tokens in doc_tokens:\n",
    "        for token in tokens:\n",
    "            if token in word_to_id:\n",
    "                corpus.append(word_to_id[token])\n",
    "    \n",
    "    corpus = np.array(corpus)\n",
    "    return doc_tokens, corpus, word_to_id, id_to_word"
   ],
   "id": "726f516434e0f4ca",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T06:25:50.761829Z",
     "start_time": "2025-06-02T06:25:50.757829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    \"\"\"\n",
    "    동시발생 행렬 생성\n",
    "    :param corpus: 말뭉치(단어 ID 목록)\n",
    "    :param vocab_size: 어휘 수\n",
    "    :param window_size: 윈도우 크기\n",
    "    :return: 동시발생 행렬\n",
    "    \"\"\"\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix"
   ],
   "id": "2418801d7dbfed8b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T06:25:51.007844Z",
     "start_time": "2025-06-02T06:25:51.002843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    \"\"\"\n",
    "    PPMI (점별 상호정보량) 생성\n",
    "    :param C: 동시발생 행렬\n",
    "    :param verbose: 진행 상황을 출력할지 여부\n",
    "    :return: PPMI 행렬\n",
    "    \"\"\"\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j] * S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total // 100 + 1) == 0:\n",
    "                    print('%.1f%% 완료' % (100 * cnt / total))\n",
    "\n",
    "    return M\n"
   ],
   "id": "4866068083df7752",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T06:25:51.289371Z",
     "start_time": "2025-06-02T06:25:51.285371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def most_similar_korean(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    \"\"\"\n",
    "    한글 단어에 대한 유사 단어 찾기\n",
    "    \"\"\"\n",
    "    if query not in word_to_id:\n",
    "        print(f'\"{query}\"를 찾을 수 없습니다.')\n",
    "        print(f'사전에 있는 단어들 (처음 20개): {list(word_to_id.keys())[:20]}')\n",
    "        return []\n",
    "\n",
    "    word_vector = np.array([word_matrix[word_to_id[query]]])\n",
    "    word_vector = word_vector.reshape(1, -1)\n",
    "    sim = cosine_similarity(word_vector, word_matrix)\n",
    "    sim = sim[0]\n",
    "\n",
    "    sim = [(id, cos) for id, cos in enumerate(sim)]\n",
    "    sim = sorted(sim, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sim[1:top+1]"
   ],
   "id": "8cad071b35a01b99",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T06:25:53.015017Z",
     "start_time": "2025-06-02T06:25:51.610896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 한글 BTS 데이터 로딩\n",
    "    try:\n",
    "        with open('./bts_korean.txt', 'r', encoding='utf-8') as f:\n",
    "            kor_docs = f.readlines()\n",
    "        \n",
    "        print(f\"로딩된 한글 문서 수: {len(kor_docs)}\")\n",
    "        \n",
    "        # 처음 몇 개 문서 미리보기\n",
    "        for id, doc in enumerate(kor_docs[:5]):\n",
    "            print(f'[{id}] : {doc.strip()[:50]}...')\n",
    "        \n",
    "        print(\"\\n=== 한글 형태소 분석 및 사전 구축 ===\")\n",
    "        doc_tokens, corpus, word_to_id, id_to_word = buildDict_korean(kor_docs)\n",
    "        \n",
    "        vocab_size = len(word_to_id)\n",
    "        print(f\"어휘 크기: {vocab_size}\")\n",
    "        print(f\"코퍼스 크기: {len(corpus)}\")\n",
    "        \n",
    "        # 상위 빈도 단어들 출력\n",
    "        print(\"상위 빈도 단어들:\")\n",
    "        for i, (word, word_id) in enumerate(list(word_to_id.items())[:10]):\n",
    "            print(f\"{word}: {word_id}\")\n",
    "        \n",
    "        print(\"\\n=== 동시발생 행렬 및 PPMI 계산 ===\")\n",
    "        window_size = 2\n",
    "        C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "        W = ppmi(C, verbose=True)\n",
    "        \n",
    "        print(f\"동시발생 행렬 형태: {C.shape}\")\n",
    "        print(f\"PPMI 행렬 형태: {W.shape}\")\n",
    "        \n",
    "        print(\"\\n=== SVD 차원 축소 ===\")\n",
    "        wordvec_size = min(100, vocab_size-1)  # 어휘 크기보다 작게 설정\n",
    "        U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=42)\n",
    "        \n",
    "        print(f\"단어 벡터 차원: {wordvec_size}\")\n",
    "        print(f\"U 행렬 형태: {U.shape}\")\n",
    "        \n",
    "        print(\"\\n=== '월드' 단어 유사도 분석 ===\")\n",
    "        # '월드' 단어 검색\n",
    "        similar_words = most_similar_korean('월드', word_to_id, id_to_word, U, top=10)\n",
    "        \n",
    "        if similar_words:\n",
    "            print(\"'월드'와 유사한 단어들:\")\n",
    "            for rank, (word_id, similarity) in enumerate(similar_words, 1):\n",
    "                print(f\"{rank}. {id_to_word[word_id]}: {similarity:.4f}\")\n",
    "        \n",
    "        # 다른 키워드들도 테스트\n",
    "        test_words = ['음악', '사랑', '세상', '꿈', '마음']\n",
    "        for test_word in test_words:\n",
    "            if test_word in word_to_id:\n",
    "                print(f\"\\n=== '{test_word}' 단어 유사도 분석 ===\")\n",
    "                similar = most_similar_korean(test_word, word_to_id, id_to_word, U, top=5)\n",
    "                if similar:\n",
    "                    for rank, (word_id, similarity) in enumerate(similar, 1):\n",
    "                        print(f\"{rank}. {id_to_word[word_id]}: {similarity:.4f}\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"'bts_korean.txt' 파일을 찾을 수 없습니다.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")"
   ],
   "id": "76015ae388929992",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로딩된 한글 문서 수: 81\n",
      "[0] : ...\n",
      "[1] : 방탄복이 총알을 막아내는 것처럼, 살아가는 동안 힘든 일을 겪는 10대, 20대가 겪는 힘...\n",
      "[2] : ...\n",
      "[3] : ...\n",
      "[4] : 2013년 방탄소년단은 《2 COOL 4 SKOOL》을 발매하며 데뷔하였고, 그 해 신인상...\n",
      "\n",
      "=== 한글 형태소 분석 및 사전 구축 ===\n",
      "어휘 크기: 1072\n",
      "코퍼스 크기: 3760\n",
      "상위 빈도 단어들:\n",
      "방탄소년단: 0\n",
      "차트: 1\n",
      "앨범: 2\n",
      "빌보드: 3\n",
      "발매: 4\n",
      "기록: 5\n",
      "미국: 6\n",
      "번째: 7\n",
      "뮤직: 8\n",
      "싱글: 9\n",
      "\n",
      "=== 동시발생 행렬 및 PPMI 계산 ===\n",
      "1.0% 완료\n",
      "2.0% 완료\n",
      "3.0% 완료\n",
      "4.0% 완료\n",
      "5.0% 완료\n",
      "6.0% 완료\n",
      "7.0% 완료\n",
      "8.0% 완료\n",
      "9.0% 완료\n",
      "10.0% 완료\n",
      "11.0% 완료\n",
      "12.0% 완료\n",
      "13.0% 완료\n",
      "14.0% 완료\n",
      "15.0% 완료\n",
      "16.0% 완료\n",
      "17.0% 완료\n",
      "18.0% 완료\n",
      "19.0% 완료\n",
      "20.0% 완료\n",
      "21.0% 완료\n",
      "22.0% 완료\n",
      "23.0% 완료\n",
      "24.0% 완료\n",
      "25.0% 완료\n",
      "26.0% 완료\n",
      "27.0% 완료\n",
      "28.0% 완료\n",
      "29.0% 완료\n",
      "30.0% 완료\n",
      "31.0% 완료\n",
      "32.0% 완료\n",
      "33.0% 완료\n",
      "34.0% 완료\n",
      "35.0% 완료\n",
      "36.0% 완료\n",
      "37.0% 완료\n",
      "38.0% 완료\n",
      "39.0% 완료\n",
      "40.0% 완료\n",
      "41.0% 완료\n",
      "42.0% 완료\n",
      "43.0% 완료\n",
      "44.0% 완료\n",
      "45.0% 완료\n",
      "46.0% 완료\n",
      "47.0% 완료\n",
      "48.0% 완료\n",
      "49.0% 완료\n",
      "50.0% 완료\n",
      "51.0% 완료\n",
      "52.0% 완료\n",
      "53.0% 완료\n",
      "54.0% 완료\n",
      "55.0% 완료\n",
      "56.0% 완료\n",
      "57.0% 완료\n",
      "58.0% 완료\n",
      "59.0% 완료\n",
      "60.0% 완료\n",
      "61.0% 완료\n",
      "62.0% 완료\n",
      "63.0% 완료\n",
      "64.0% 완료\n",
      "65.0% 완료\n",
      "66.0% 완료\n",
      "67.0% 완료\n",
      "68.0% 완료\n",
      "69.0% 완료\n",
      "70.0% 완료\n",
      "71.0% 완료\n",
      "72.0% 완료\n",
      "73.0% 완료\n",
      "74.0% 완료\n",
      "75.0% 완료\n",
      "76.0% 완료\n",
      "77.0% 완료\n",
      "78.0% 완료\n",
      "79.0% 완료\n",
      "80.0% 완료\n",
      "81.0% 완료\n",
      "82.0% 완료\n",
      "83.0% 완료\n",
      "84.0% 완료\n",
      "85.0% 완료\n",
      "86.0% 완료\n",
      "87.0% 완료\n",
      "88.0% 완료\n",
      "89.0% 완료\n",
      "90.0% 완료\n",
      "91.0% 완료\n",
      "92.0% 완료\n",
      "93.0% 완료\n",
      "94.0% 완료\n",
      "95.0% 완료\n",
      "96.0% 완료\n",
      "97.0% 완료\n",
      "98.0% 완료\n",
      "99.0% 완료\n",
      "동시발생 행렬 형태: (1072, 1072)\n",
      "PPMI 행렬 형태: (1072, 1072)\n",
      "\n",
      "=== SVD 차원 축소 ===\n",
      "단어 벡터 차원: 100\n",
      "U 행렬 형태: (1072, 100)\n",
      "\n",
      "=== '월드' 단어 유사도 분석 ===\n",
      "'월드'와 유사한 단어들:\n",
      "1. 와이드: 0.6951\n",
      "2. 고베: 0.5584\n",
      "3. 도시: 0.5218\n",
      "4. 아레나: 0.4845\n",
      "5. 걸치다: 0.4736\n",
      "6. 기념: 0.4710\n",
      "7. 스타: 0.4645\n",
      "8. 요코하마: 0.4639\n",
      "9. 뽑다: 0.4603\n",
      "10. 액트: 0.4267\n",
      "\n",
      "=== '음악' 단어 유사도 분석 ===\n",
      "1. 완성: 0.6172\n",
      "2. 쓰다: 0.5775\n",
      "3. 가치: 0.5488\n",
      "4. 질료: 0.5481\n",
      "5. 스스로: 0.5392\n",
      "\n",
      "=== '사랑' 단어 유사도 분석 ===\n",
      "1. 끝나다: 0.5705\n",
      "2. 담기다: 0.5501\n",
      "3. 마음: 0.4938\n",
      "4. 작고: 0.4893\n",
      "5. 붙잡다: 0.4542\n",
      "\n",
      "=== '마음' 단어 유사도 분석 ===\n",
      "1. 붙잡다: 0.8529\n",
      "2. 넘치다: 0.8344\n",
      "3. 표현: 0.7294\n",
      "4. 패기: 0.6436\n",
      "5. 담기다: 0.5886\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "30e47447f0341c83"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
